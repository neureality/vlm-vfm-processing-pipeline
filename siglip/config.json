{
    "batch_size": 30,
    "pixel_values_shape": [30, 3, 14, 14448],
    "drop_vision_last_layer": false,
    "attention_dropout": 0.0,
    "hidden_act": "gelu_pytorch_tanh",
    "hidden_size": 1152,
    "image_size": 980,
    "intermediate_size": 4304,
    "layer_norm_eps": 1e-06,
    "model_type": "siglip_vision_model",
    "num_attention_heads": 16,
    "num_channels": 3,
    "num_hidden_layers": 27,
    "patch_size": 14,
    "transformers_version": "4.45.2"
}