{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T08:15:20.615009Z",
     "iopub.status.busy": "2025-04-03T08:15:20.614701Z",
     "iopub.status.idle": "2025-04-03T08:15:21.120622Z",
     "shell.execute_reply": "2025-04-03T08:15:21.120051Z"
    }
   },
   "outputs": [],
   "source": [
    "from polygraphy.backend.onnxrt import OnnxrtRunner, SessionFromOnnx\n",
    "from polygraphy.backend.trt import TrtRunner, EngineFromNetwork, NetworkFromOnnxPath, Profile\n",
    "from polygraphy.comparator import Comparator, DataLoader\n",
    "from polygraphy.backend.trt import CreateConfig as CreateTrtConfig, SaveEngine\n",
    "import numpy as np\n",
    "import tensorrt as trt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T08:15:21.122870Z",
     "iopub.status.busy": "2025-04-03T08:15:21.122524Z",
     "iopub.status.idle": "2025-04-03T08:15:21.125291Z",
     "shell.execute_reply": "2025-04-03T08:15:21.124825Z"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_ENGINE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T08:15:21.127000Z",
     "iopub.status.busy": "2025-04-03T08:15:21.126712Z",
     "iopub.status.idle": "2025-04-03T08:15:21.129453Z",
     "shell.execute_reply": "2025-04-03T08:15:21.128911Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"/home/ubuntu/vlm-vfm-processing-pipeline/models/vfm_fix_outofrange_fp16.onnx\"\n",
    "# engine_save_path = \"/home/ubuntu/vlm-vfm-processing-pipeline/models/vfm.engine\"\n",
    "engine_save_path = \"/home/ubuntu/vlm-vfm-processing-pipeline/models/model.plen\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T08:15:21.131134Z",
     "iopub.status.busy": "2025-04-03T08:15:21.130869Z",
     "iopub.status.idle": "2025-04-03T08:15:21.137650Z",
     "shell.execute_reply": "2025-04-03T08:15:21.137171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] TF32 is disabled by default. Turn on TF32 for better performance with minor accuracy differences.\n"
     ]
    }
   ],
   "source": [
    "profiles = [\n",
    "    Profile()\n",
    "    .add('patch_attn_mask', min=[30, 1, 1032], opt=[30, 1, 1032], max=[30, 1, 1032])\n",
    "    .add('all_pixel_values', min=[30, 3, 14, 14448], opt=[30, 3, 14, 14448], max=[30, 3, 14, 14448])\n",
    "    ]\n",
    "\n",
    "create_trt_config = CreateTrtConfig(\n",
    "    profiles=profiles,\n",
    "    # hardware_compatibility_level=trt.HardwareCompatibilityLevel.AMPERE_PLUS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T08:15:21.168819Z",
     "iopub.status.busy": "2025-04-03T08:15:21.168357Z",
     "iopub.status.idle": "2025-04-03T08:20:36.717555Z",
     "shell.execute_reply": "2025-04-03T08:20:36.716968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Configuring with profiles:[\n",
      "        Profile 0:\n",
      "            {patch_attn_mask [min=[30, 1, 1032], opt=[30, 1, 1032], max=[30, 1, 1032]],\n",
      "             all_pixel_values [min=[30, 3, 14, 14448], opt=[30, 3, 14, 14448], max=[30, 3, 14, 14448]]}\n",
      "    ]\n",
      "\u001b[38;5;11m[W] profileSharing0806 is on by default in TensorRT 10.0. This flag is deprecated and has no effect.\u001b[0m\n",
      "\u001b[38;5;14m[I] Building engine with configuration:\n",
      "    Flags                  | []\n",
      "    Engine Capability      | EngineCapability.STANDARD\n",
      "    Memory Pools           | [WORKSPACE: 22515.75 MiB, TACTIC_DRAM: 22515.75 MiB, TACTIC_SHARED_MEMORY: 1024.00 MiB]\n",
      "    Tactic Sources         | [EDGE_MASK_CONVOLUTIONS, JIT_CONVOLUTIONS]\n",
      "    Profiling Verbosity    | ProfilingVerbosity.DETAILED\n",
      "    Preview Features       | [PROFILE_SHARING_0806]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;10m[I] Finished engine building in 138.729 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Configuring with profiles:[\n",
      "        Profile 0:\n",
      "            {patch_attn_mask [min=[30, 1, 1032], opt=[30, 1, 1032], max=[30, 1, 1032]],\n",
      "             all_pixel_values [min=[30, 3, 14, 14448], opt=[30, 3, 14, 14448], max=[30, 3, 14, 14448]]}\n",
      "    ]\n",
      "\u001b[38;5;14m[I] Building engine with configuration:\n",
      "    Flags                  | []\n",
      "    Engine Capability      | EngineCapability.STANDARD\n",
      "    Memory Pools           | [WORKSPACE: 22515.75 MiB, TACTIC_DRAM: 22515.75 MiB, TACTIC_SHARED_MEMORY: 1024.00 MiB]\n",
      "    Tactic Sources         | [EDGE_MASK_CONVOLUTIONS, JIT_CONVOLUTIONS]\n",
      "    Profiling Verbosity    | ProfilingVerbosity.DETAILED\n",
      "    Preview Features       | [PROFILE_SHARING_0806]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;10m[I] Finished engine building in 143.899 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Saving engine to /home/ubuntu/vlm-vfm-processing-pipeline/models/model.plen\n"
     ]
    }
   ],
   "source": [
    "build_onnxrt_session = SessionFromOnnx(model_path)\n",
    "build_engine = EngineFromNetwork(NetworkFromOnnxPath(model_path), config=create_trt_config)\n",
    "\n",
    "if SAVE_ENGINE:\n",
    "    # Save the engine to disk\n",
    "    # Note: This is a blocking call and will take some time to complete\n",
    "    engine = build_engine()\n",
    "    SaveEngine(build_engine, engine_save_path)()\n",
    "    \n",
    "runners = [\n",
    "    OnnxrtRunner(build_onnxrt_session),\n",
    "    TrtRunner(build_engine),\n",
    "]\n",
    "\n",
    "data_loader = [{\n",
    "    \"all_pixel_values\": np.zeros((30, 3, 14, 14448), dtype=np.float32),\n",
    "    \"patch_attn_mask\": np.zeros((30, 1, 1032), dtype=np.bool_),\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T08:20:36.719823Z",
     "iopub.status.busy": "2025-04-03T08:20:36.719521Z",
     "iopub.status.idle": "2025-04-03T08:20:37.943229Z",
     "shell.execute_reply": "2025-04-03T08:20:37.942568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;9m[!] Could not automatically determine model type for: /home/ubuntu/vlm-vfm-processing-pipeline/models/model.plen\r\n",
      "    Please explicitly specify the type with the --model-type option\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Inspect the engine to verify that it was built correctly\n",
    "cmd = f\"polygraphy inspect model {engine_save_path}\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T08:20:37.945620Z",
     "iopub.status.busy": "2025-04-03T08:20:37.945129Z",
     "iopub.status.idle": "2025-04-03T08:20:53.672805Z",
     "shell.execute_reply": "2025-04-03T08:20:53.672143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Loading bytes from /home/ubuntu/vlm-vfm-processing-pipeline/models/model.plen\n"
     ]
    }
   ],
   "source": [
    "# Run inference with trt \n",
    "import torch\n",
    "from polygraphy.backend.common import BytesFromPath\n",
    "from polygraphy.backend.trt import EngineFromBytes, TrtRunner\n",
    "load_engine = EngineFromBytes(BytesFromPath(engine_save_path))\n",
    "\n",
    "with TrtRunner(load_engine) as runner:\n",
    "        all_pixel_values = torch.load(\n",
    "            \"/home/ubuntu/vlm-vfm-processing-pipeline/test_data/all_pixel_values.pkl\",\n",
    "            weights_only=True,\n",
    "            map_location=\"cuda\",\n",
    "        )\n",
    "        patch_attn_mask = torch.load(\n",
    "            \"/home/ubuntu/vlm-vfm-processing-pipeline/test_data/patch_attn_mask.pkl\",\n",
    "            weights_only=True,\n",
    "            map_location=\"cuda\",\n",
    "        )\n",
    "\n",
    "        # NOTE: The runner owns the output buffers and is free to reuse them between `infer()` calls.\n",
    "        # Thus, if you want to store results from multiple inferences, you should use `copy.deepcopy()`.\n",
    "        outputs = runner.infer(feed_dict={\n",
    "            \"all_pixel_values\": all_pixel_values,\n",
    "            \"patch_attn_mask\": patch_attn_mask,\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T08:20:53.678061Z",
     "iopub.status.busy": "2025-04-03T08:20:53.677431Z",
     "iopub.status.idle": "2025-04-03T08:20:53.685438Z",
     "shell.execute_reply": "2025-04-03T08:20:53.684856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['vision_embedding'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T08:20:53.687662Z",
     "iopub.status.busy": "2025-04-03T08:20:53.687288Z",
     "iopub.status.idle": "2025-04-03T08:25:41.419551Z",
     "shell.execute_reply": "2025-04-03T08:25:41.418959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;14m[I] onnxrt-runner-N0-04/03/25-08:20:36  | Activating and starting inference\u001b[0m\n",
      "\u001b[38;5;14m[I] Creating ONNX-Runtime Inference Session with providers: ['CPUExecutionProvider']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] onnxrt-runner-N0-04/03/25-08:20:36 \n",
      "    ---- Inference Input(s) ----\n",
      "    {all_pixel_values [dtype=float32, shape=(30, 3, 14, 14448)],\n",
      "     patch_attn_mask [dtype=bool, shape=(30, 1, 1032)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] onnxrt-runner-N0-04/03/25-08:20:36 \n",
      "    ---- Inference Output(s) ----\n",
      "    {vision_embedding [dtype=float32, shape=(30, 64, 3584)]}\n",
      "\u001b[38;5;10m[I] onnxrt-runner-N0-04/03/25-08:20:36  | Completed 1 iteration(s) in 1.284e+05 ms | Average inference time: 1.284e+05 ms.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;14m[I] trt-runner-N0-04/03/25-08:20:36     | Activating and starting inference\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Configuring with profiles:[\n",
      "        Profile 0:\n",
      "            {patch_attn_mask [min=[30, 1, 1032], opt=[30, 1, 1032], max=[30, 1, 1032]],\n",
      "             all_pixel_values [min=[30, 3, 14, 14448], opt=[30, 3, 14, 14448], max=[30, 3, 14, 14448]]}\n",
      "    ]\n",
      "\u001b[38;5;14m[I] Building engine with configuration:\n",
      "    Flags                  | []\n",
      "    Engine Capability      | EngineCapability.STANDARD\n",
      "    Memory Pools           | [WORKSPACE: 22515.75 MiB, TACTIC_DRAM: 22515.75 MiB, TACTIC_SHARED_MEMORY: 1024.00 MiB]\n",
      "    Tactic Sources         | [EDGE_MASK_CONVOLUTIONS, JIT_CONVOLUTIONS]\n",
      "    Profiling Verbosity    | ProfilingVerbosity.DETAILED\n",
      "    Preview Features       | [PROFILE_SHARING_0806]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;10m[I] Finished engine building in 144.412 seconds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] trt-runner-N0-04/03/25-08:20:36    \n",
      "    ---- Inference Input(s) ----\n",
      "    {all_pixel_values [dtype=float32, shape=(30, 3, 14, 14448)],\n",
      "     patch_attn_mask [dtype=bool, shape=(30, 1, 1032)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] trt-runner-N0-04/03/25-08:20:36    \n",
      "    ---- Inference Output(s) ----\n",
      "    {vision_embedding [dtype=float32, shape=(30, 64, 3584)]}\n",
      "\u001b[38;5;10m[I] trt-runner-N0-04/03/25-08:20:36     | Completed 1 iteration(s) in 1999 ms | Average inference time: 1999 ms.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Compare the results from the ONNX Runtime and TensorRT engines\n",
    "results = Comparator.run(runners, data_loader=data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T08:25:41.426543Z",
     "iopub.status.busy": "2025-04-03T08:25:41.426334Z",
     "iopub.status.idle": "2025-04-03T08:25:43.404492Z",
     "shell.execute_reply": "2025-04-03T08:25:43.403818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;14m[I] Accuracy Comparison | onnxrt-runner-N0-04/03/25-08:20:36 vs. trt-runner-N0-04/03/25-08:20:36\u001b[0m\n",
      "\u001b[38;5;14m[I]     Comparing Output: 'vision_embedding' (dtype=float32, shape=(30, 64, 3584)) with 'vision_embedding' (dtype=float32, shape=(30, 64, 3584))\u001b[0m\n",
      "[I]         Tolerance: [abs=1e-05, rel=1e-05] | Checking elemwise error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I]         onnxrt-runner-N0-04/03/25-08:20:36: vision_embedding | Stats: mean=-0.00056166, std-dev=0.51486, var=0.26509, median=-0.00073969, min=-6.8264 at (0, 8, 1929), max=9.062 at (0, 63, 2570), avg-magnitude=0.3349, p90=0.49777, p95=0.75957, p99=1.5146\n",
      "[I]             ---- Histogram ----\n",
      "                Bin Range        |  Num Elems | Visualization\n",
      "                (-6.83 , -5.24 ) |        390 | \n",
      "                (-5.24 , -3.65 ) |       1800 | \n",
      "                (-3.65 , -2.06 ) |      20790 | \n",
      "                (-2.06 , -0.471) |     726710 | ####\n",
      "                (-0.471, 1.12  ) |    5977060 | ########################################\n",
      "                (1.12  , 2.71  ) |     145260 | \n",
      "                (2.71  , 4.3   ) |       7740 | \n",
      "                (4.3   , 5.88  ) |        980 | \n",
      "                (5.88  , 7.47  ) |        480 | \n",
      "                (7.47  , 9.06  ) |         70 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I]         trt-runner-N0-04/03/25-08:20:36: vision_embedding | Stats: mean=-0.00056189, std-dev=0.51487, var=0.26509, median=-0.00074273, min=-6.8263 at (0, 8, 1929), max=9.0618 at (0, 63, 2570), avg-magnitude=0.33491, p90=0.49779, p95=0.75954, p99=1.5143\n",
      "[I]             ---- Histogram ----\n",
      "                Bin Range        |  Num Elems | Visualization\n",
      "                (-6.83 , -5.24 ) |        390 | \n",
      "                (-5.24 , -3.65 ) |       1800 | \n",
      "                (-3.65 , -2.06 ) |      20790 | \n",
      "                (-2.06 , -0.471) |     726660 | ####\n",
      "                (-0.471, 1.12  ) |    5977110 | ########################################\n",
      "                (1.12  , 2.71  ) |     145260 | \n",
      "                (2.71  , 4.3   ) |       7740 | \n",
      "                (4.3   , 5.88  ) |        980 | \n",
      "                (5.88  , 7.47  ) |        480 | \n",
      "                (7.47  , 9.06  ) |         70 | \n",
      "[I]         Error Metrics: vision_embedding\n",
      "[I]             Minimum Required Tolerance: elemwise error | [abs=0.0030964] OR [rel=77.412] (requirements may be lower if both abs/rel tolerances are set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I]             Absolute Difference | Stats: mean=7.1331e-05, std-dev=0.0001252, var=1.5674e-08, median=3.2037e-05, min=0 at (0, 0, 1913), max=0.0030964 at (1, 46, 775), avg-magnitude=7.1331e-05, p90=0.00016517, p95=0.00027137, p99=0.00063539\n",
      "[I]                 ---- Histogram ----\n",
      "                    Bin Range            |  Num Elems | Visualization\n",
      "                    (0       , 0.00031 ) |    6602900 | ########################################\n",
      "                    (0.00031 , 0.000619) |     205190 | #\n",
      "                    (0.000619, 0.000929) |      49870 | \n",
      "                    (0.000929, 0.00124 ) |      15720 | \n",
      "                    (0.00124 , 0.00155 ) |       4760 | \n",
      "                    (0.00155 , 0.00186 ) |       1760 | \n",
      "                    (0.00186 , 0.00217 ) |        700 | \n",
      "                    (0.00217 , 0.00248 ) |        280 | \n",
      "                    (0.00248 , 0.00279 ) |         40 | \n",
      "                    (0.00279 , 0.0031  ) |         60 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I]             Relative Difference | Stats: mean=0.0017297, std-dev=0.14582, var=0.021263, median=0.00015721, min=0 at (0, 0, 1913), max=77.412 at (1, 5, 2535), avg-magnitude=0.0017297, p90=0.0012476, p95=0.0025453, p99=0.012876\n",
      "[I]                 ---- Histogram ----\n",
      "                    Bin Range    |  Num Elems | Visualization\n",
      "                    (0   , 7.74) |    6881150 | ########################################\n",
      "                    (7.74, 15.5) |         90 | \n",
      "                    (15.5, 23.2) |         20 | \n",
      "                    (23.2, 31  ) |          0 | \n",
      "                    (31  , 38.7) |          0 | \n",
      "                    (38.7, 46.4) |          0 | \n",
      "                    (46.4, 54.2) |          0 | \n",
      "                    (54.2, 61.9) |          0 | \n",
      "                    (61.9, 69.7) |          0 | \n",
      "                    (69.7, 77.4) |         20 | \n",
      "\u001b[38;5;9m[E]         FAILED | Output: 'vision_embedding' | Difference exceeds tolerance (rel=1e-05, abs=1e-05)\u001b[0m\n",
      "\u001b[38;5;9m[E]     FAILED | Mismatched outputs: ['vision_embedding']\u001b[0m\n",
      "\u001b[38;5;9m[E] Accuracy Summary | onnxrt-runner-N0-04/03/25-08:20:36 vs. trt-runner-N0-04/03/25-08:20:36 | Passed: 0/1 iterations | Pass Rate: 0.0%\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([(('onnxrt-runner-N0-04/03/25-08:20:36', 'trt-runner-N0-04/03/25-08:20:36'), [OrderedDict([('vision_embedding', <polygraphy.comparator.compare.OutputCompareResult object at 0x7fa3b815dff0>)])])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comparator.compare_accuracy(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
