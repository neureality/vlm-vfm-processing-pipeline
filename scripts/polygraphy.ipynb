{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polygraphy.backend.onnxrt import OnnxrtRunner, SessionFromOnnx\n",
    "from polygraphy.backend.trt import TrtRunner, EngineFromNetwork, NetworkFromOnnxPath, Profile\n",
    "from polygraphy.comparator import Comparator, DataLoader\n",
    "from polygraphy.backend.trt import CreateConfig as CreateTrtConfig, SaveEngine\n",
    "import numpy as np\n",
    "import tensorrt as trt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_ENGINE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/ubuntu/vlm-vfm-processing-pipeline/models/vfm_fix_outofrange_fp16.onnx\"\n",
    "engine_save_path = \"/home/ubuntu/vlm-vfm-processing-pipeline/models/vfm.engine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] TF32 is disabled by default. Turn on TF32 for better performance with minor accuracy differences.\n"
     ]
    }
   ],
   "source": [
    "profiles = [\n",
    "    Profile()\n",
    "    .add('patch_attn_mask', min=[30, 1, 1032], opt=[30, 1, 1032], max=[30, 1, 1032])\n",
    "    .add('all_pixel_values', min=[30, 3, 14, 14448], opt=[30, 3, 14, 14448], max=[30, 3, 14, 14448])\n",
    "    ]\n",
    "\n",
    "create_trt_config = CreateTrtConfig(\n",
    "    profiles=profiles,\n",
    "    # hardware_compatibility_level=trt.HardwareCompatibilityLevel.AMPERE_PLUS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Configuring with profiles:[\n",
      "        Profile 0:\n",
      "            {patch_attn_mask [min=[30, 1, 1032], opt=[30, 1, 1032], max=[30, 1, 1032]],\n",
      "             all_pixel_values [min=[30, 3, 14, 14448], opt=[30, 3, 14, 14448], max=[30, 3, 14, 14448]]}\n",
      "    ]\n",
      "\u001b[38;5;11m[W] profileSharing0806 is on by default in TensorRT 10.0. This flag is deprecated and has no effect.\u001b[0m\n",
      "\u001b[38;5;14m[I] Building engine with configuration:\n",
      "    Flags                  | []\n",
      "    Engine Capability      | EngineCapability.STANDARD\n",
      "    Memory Pools           | [WORKSPACE: 22515.75 MiB, TACTIC_DRAM: 22515.75 MiB, TACTIC_SHARED_MEMORY: 1024.00 MiB]\n",
      "    Tactic Sources         | [EDGE_MASK_CONVOLUTIONS, JIT_CONVOLUTIONS]\n",
      "    Profiling Verbosity    | ProfilingVerbosity.DETAILED\n",
      "    Preview Features       | [PROFILE_SHARING_0806]\u001b[0m\n",
      "\u001b[38;5;10m[I] Finished engine building in 95.400 seconds\u001b[0m\n",
      "[I] Configuring with profiles:[\n",
      "        Profile 0:\n",
      "            {patch_attn_mask [min=[30, 1, 1032], opt=[30, 1, 1032], max=[30, 1, 1032]],\n",
      "             all_pixel_values [min=[30, 3, 14, 14448], opt=[30, 3, 14, 14448], max=[30, 3, 14, 14448]]}\n",
      "    ]\n",
      "\u001b[38;5;14m[I] Building engine with configuration:\n",
      "    Flags                  | []\n",
      "    Engine Capability      | EngineCapability.STANDARD\n",
      "    Memory Pools           | [WORKSPACE: 22515.75 MiB, TACTIC_DRAM: 22515.75 MiB, TACTIC_SHARED_MEMORY: 1024.00 MiB]\n",
      "    Tactic Sources         | [EDGE_MASK_CONVOLUTIONS, JIT_CONVOLUTIONS]\n",
      "    Profiling Verbosity    | ProfilingVerbosity.DETAILED\n",
      "    Preview Features       | [PROFILE_SHARING_0806]\u001b[0m\n",
      "\u001b[38;5;10m[I] Finished engine building in 96.916 seconds\u001b[0m\n",
      "[I] Saving engine to /home/ubuntu/vlm-vfm-processing-pipeline/models/vfm.engine\n"
     ]
    }
   ],
   "source": [
    "build_onnxrt_session = SessionFromOnnx(model_path)\n",
    "build_engine = EngineFromNetwork(NetworkFromOnnxPath(model_path), config=create_trt_config)\n",
    "\n",
    "if SAVE_ENGINE:\n",
    "    # Save the engine to disk\n",
    "    # Note: This is a blocking call and will take some time to complete\n",
    "    engine = build_engine()\n",
    "    SaveEngine(build_engine, engine_save_path)()\n",
    "    \n",
    "runners = [\n",
    "    OnnxrtRunner(build_onnxrt_session),\n",
    "    TrtRunner(build_engine),\n",
    "]\n",
    "\n",
    "data_loader = [{\n",
    "    \"all_pixel_values\": np.zeros((30, 3, 14, 14448), dtype=np.float32),\n",
    "    \"patch_attn_mask\": np.zeros((30, 1, 1032), dtype=np.bool_),\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Loading bytes from /home/ubuntu/vlm-vfm-processing-pipeline/models/vfm.engine\n",
      "\u001b[38;5;11m[W] hasImplicitBatchDimension is deprecated and always return false.\u001b[0m\n",
      "[I] ==== TensorRT Engine ====\n",
      "    Name: Unnamed Network 0 | Explicit Batch Engine\n",
      "    \n",
      "    ---- 2 Engine Input(s) ----\n",
      "    {all_pixel_values [dtype=float32, shape=(30, 3, 14, 14448)],\n",
      "     patch_attn_mask [dtype=bool, shape=(30, 1, 1032)]}\n",
      "    \n",
      "    ---- 1 Engine Output(s) ----\n",
      "    {vision_embedding [dtype=float32, shape=(30, 64, 3584)]}\n",
      "    \n",
      "    ---- Memory ----\n",
      "    Device Memory: 7662036480 bytes\n",
      "    \n",
      "    ---- 1 Profile(s) (3 Tensor(s) Each) ----\n",
      "    - Profile: 0\n",
      "        Tensor: all_pixel_values          (Input), Index: 0 | Shapes: min=(30, 3, 14, 14448), opt=(30, 3, 14, 14448), max=(30, 3, 14, 14448)\n",
      "        Tensor: patch_attn_mask           (Input), Index: 1 | Shapes: min=(30, 1, 1032), opt=(30, 1, 1032), max=(30, 1, 1032)\n",
      "        Tensor: vision_embedding         (Output), Index: 2 | Shape: (30, 64, 3584)\n",
      "    \n",
      "    ---- 476 Layer(s) ----\n"
     ]
    }
   ],
   "source": [
    "# Inspect the engine to verify that it was built correctly\n",
    "cmd = f\"polygraphy inspect model {engine_save_path}\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] Loading bytes from /home/ubuntu/vlm-vfm-processing-pipeline/models/vfm.engine\n"
     ]
    }
   ],
   "source": [
    "# Run inference with trt \n",
    "import torch\n",
    "from polygraphy.backend.common import BytesFromPath\n",
    "from polygraphy.backend.trt import EngineFromBytes, TrtRunner\n",
    "load_engine = EngineFromBytes(BytesFromPath(engine_save_path))\n",
    "\n",
    "with TrtRunner(load_engine) as runner:\n",
    "        all_pixel_values = torch.load(\n",
    "            \"/home/ubuntu/vlm-vfm-processing-pipeline/test_data/all_pixel_values.pkl\",\n",
    "            weights_only=True,\n",
    "            map_location=\"cuda\",\n",
    "        )\n",
    "        patch_attn_mask = torch.load(\n",
    "            \"/home/ubuntu/vlm-vfm-processing-pipeline/test_data/patch_attn_mask.pkl\",\n",
    "            weights_only=True,\n",
    "            map_location=\"cuda\",\n",
    "        )\n",
    "\n",
    "        # NOTE: The runner owns the output buffers and is free to reuse them between `infer()` calls.\n",
    "        # Thus, if you want to store results from multiple inferences, you should use `copy.deepcopy()`.\n",
    "        outputs = runner.infer(feed_dict={\n",
    "            \"all_pixel_values\": all_pixel_values,\n",
    "            \"patch_attn_mask\": patch_attn_mask,\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['vision_embedding'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;14m[I] onnxrt-runner-N0-03/26/25-14:46:29  | Activating and starting inference\u001b[0m\n",
      "\u001b[38;5;14m[I] Creating ONNX-Runtime Inference Session with providers: ['CPUExecutionProvider']\u001b[0m\n",
      "[I] onnxrt-runner-N0-03/26/25-14:46:29 \n",
      "    ---- Inference Input(s) ----\n",
      "    {all_pixel_values [dtype=float32, shape=(30, 3, 14, 14448)],\n",
      "     patch_attn_mask [dtype=bool, shape=(30, 1, 1032)]}\n",
      "[I] onnxrt-runner-N0-03/26/25-14:46:29 \n",
      "    ---- Inference Output(s) ----\n",
      "    {vision_embedding [dtype=float32, shape=(30, 64, 3584)]}\n",
      "\u001b[38;5;10m[I] onnxrt-runner-N0-03/26/25-14:46:29  | Completed 1 iteration(s) in 1.295e+05 ms | Average inference time: 1.295e+05 ms.\u001b[0m\n",
      "\u001b[38;5;14m[I] trt-runner-N0-03/26/25-14:46:29     | Activating and starting inference\u001b[0m\n",
      "[I] Configuring with profiles:[\n",
      "        Profile 0:\n",
      "            {patch_attn_mask [min=[30, 1, 1032], opt=[30, 1, 1032], max=[30, 1, 1032]],\n",
      "             all_pixel_values [min=[30, 3, 14, 14448], opt=[30, 3, 14, 14448], max=[30, 3, 14, 14448]]}\n",
      "    ]\n",
      "\u001b[38;5;11m[W] profileSharing0806 is on by default in TensorRT 10.0. This flag is deprecated and has no effect.\u001b[0m\n",
      "\u001b[38;5;14m[I] Building engine with configuration:\n",
      "    Flags                  | []\n",
      "    Engine Capability      | EngineCapability.STANDARD\n",
      "    Memory Pools           | [WORKSPACE: 22515.75 MiB, TACTIC_DRAM: 22515.75 MiB, TACTIC_SHARED_MEMORY: 1024.00 MiB]\n",
      "    Tactic Sources         | [EDGE_MASK_CONVOLUTIONS, JIT_CONVOLUTIONS]\n",
      "    Profiling Verbosity    | ProfilingVerbosity.DETAILED\n",
      "    Preview Features       | [PROFILE_SHARING_0806]\u001b[0m\n",
      "\u001b[38;5;10m[I] Finished engine building in 96.790 seconds\u001b[0m\n",
      "[I] trt-runner-N0-03/26/25-14:46:29    \n",
      "    ---- Inference Input(s) ----\n",
      "    {all_pixel_values [dtype=float32, shape=(30, 3, 14, 14448)],\n",
      "     patch_attn_mask [dtype=bool, shape=(30, 1, 1032)]}\n",
      "[I] trt-runner-N0-03/26/25-14:46:29    \n",
      "    ---- Inference Output(s) ----\n",
      "    {vision_embedding [dtype=float32, shape=(30, 64, 3584)]}\n",
      "\u001b[38;5;10m[I] trt-runner-N0-03/26/25-14:46:29     | Completed 1 iteration(s) in 1987 ms | Average inference time: 1987 ms.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Compare the results from the ONNX Runtime and TensorRT engines\n",
    "results = Comparator.run(runners, data_loader=data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;14m[I] Accuracy Comparison | onnxrt-runner-N0-03/26/25-14:46:29 vs. trt-runner-N0-03/26/25-14:46:29\u001b[0m\n",
      "\u001b[38;5;14m[I]     Comparing Output: 'vision_embedding' (dtype=float32, shape=(30, 64, 3584)) with 'vision_embedding' (dtype=float32, shape=(30, 64, 3584))\u001b[0m\n",
      "[I]         Tolerance: [abs=1e-05, rel=1e-05] | Checking elemwise error\n",
      "[I]         onnxrt-runner-N0-03/26/25-14:46:29: vision_embedding | Stats: mean=-0.00056166, std-dev=0.51486, var=0.26509, median=-0.00073969, min=-6.8264 at (0, 8, 1929), max=9.062 at (0, 63, 2570), avg-magnitude=0.3349, p90=0.49777, p95=0.75957, p99=1.5146\n",
      "[I]             ---- Histogram ----\n",
      "                Bin Range        |  Num Elems | Visualization\n",
      "                (-6.83 , -5.24 ) |        390 | \n",
      "                (-5.24 , -3.65 ) |       1800 | \n",
      "                (-3.65 , -2.06 ) |      20790 | \n",
      "                (-2.06 , -0.471) |     726710 | ####\n",
      "                (-0.471, 1.12  ) |    5977060 | ########################################\n",
      "                (1.12  , 2.71  ) |     145260 | \n",
      "                (2.71  , 4.3   ) |       7740 | \n",
      "                (4.3   , 5.88  ) |        980 | \n",
      "                (5.88  , 7.47  ) |        480 | \n",
      "                (7.47  , 9.06  ) |         70 | \n",
      "[I]         trt-runner-N0-03/26/25-14:46:29: vision_embedding | Stats: mean=-0.00056189, std-dev=0.51487, var=0.26509, median=-0.00074258, min=-6.8263 at (0, 8, 1929), max=9.0618 at (0, 63, 2570), avg-magnitude=0.33491, p90=0.49779, p95=0.75954, p99=1.5143\n",
      "[I]             ---- Histogram ----\n",
      "                Bin Range        |  Num Elems | Visualization\n",
      "                (-6.83 , -5.24 ) |        390 | \n",
      "                (-5.24 , -3.65 ) |       1800 | \n",
      "                (-3.65 , -2.06 ) |      20790 | \n",
      "                (-2.06 , -0.471) |     726660 | ####\n",
      "                (-0.471, 1.12  ) |    5977110 | ########################################\n",
      "                (1.12  , 2.71  ) |     145260 | \n",
      "                (2.71  , 4.3   ) |       7740 | \n",
      "                (4.3   , 5.88  ) |        980 | \n",
      "                (5.88  , 7.47  ) |        480 | \n",
      "                (7.47  , 9.06  ) |         70 | \n",
      "[I]         Error Metrics: vision_embedding\n",
      "[I]             Minimum Required Tolerance: elemwise error | [abs=0.0030984] OR [rel=74.755] (requirements may be lower if both abs/rel tolerances are set)\n",
      "[I]             Absolute Difference | Stats: mean=7.1337e-05, std-dev=0.00012522, var=1.568e-08, median=3.2023e-05, min=0 at (0, 0, 3559), max=0.0030984 at (1, 46, 775), avg-magnitude=7.1337e-05, p90=0.0001651, p95=0.00027144, p99=0.00063515\n",
      "[I]                 ---- Histogram ----\n",
      "                    Bin Range          |  Num Elems | Visualization\n",
      "                    (0      , 0.00031) |    6602920 | ########################################\n",
      "                    (0.00031, 0.00062) |     205370 | #\n",
      "                    (0.00062, 0.00093) |      49670 | \n",
      "                    (0.00093, 0.00124) |      15700 | \n",
      "                    (0.00124, 0.00155) |       4800 | \n",
      "                    (0.00155, 0.00186) |       1720 | \n",
      "                    (0.00186, 0.00217) |        720 | \n",
      "                    (0.00217, 0.00248) |        280 | \n",
      "                    (0.00248, 0.00279) |         40 | \n",
      "                    (0.00279, 0.0031 ) |         60 | \n",
      "[I]             Relative Difference | Stats: mean=0.0017202, std-dev=0.143, var=0.020449, median=0.00015723, min=0 at (0, 0, 3559), max=74.755 at (1, 5, 2535), avg-magnitude=0.0017202, p90=0.0012482, p95=0.0025444, p99=0.012885\n",
      "[I]                 ---- Histogram ----\n",
      "                    Bin Range    |  Num Elems | Visualization\n",
      "                    (0   , 7.48) |    6881160 | ########################################\n",
      "                    (7.48, 15  ) |         80 | \n",
      "                    (15  , 22.4) |          0 | \n",
      "                    (22.4, 29.9) |         20 | \n",
      "                    (29.9, 37.4) |          0 | \n",
      "                    (37.4, 44.9) |          0 | \n",
      "                    (44.9, 52.3) |          0 | \n",
      "                    (52.3, 59.8) |          0 | \n",
      "                    (59.8, 67.3) |          0 | \n",
      "                    (67.3, 74.8) |         20 | \n",
      "\u001b[38;5;9m[E]         FAILED | Output: 'vision_embedding' | Difference exceeds tolerance (rel=1e-05, abs=1e-05)\u001b[0m\n",
      "\u001b[38;5;9m[E]     FAILED | Mismatched outputs: ['vision_embedding']\u001b[0m\n",
      "\u001b[38;5;9m[E] Accuracy Summary | onnxrt-runner-N0-03/26/25-14:46:29 vs. trt-runner-N0-03/26/25-14:46:29 | Passed: 0/1 iterations | Pass Rate: 0.0%\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([(('onnxrt-runner-N0-03/26/25-14:46:29', 'trt-runner-N0-03/26/25-14:46:29'), [OrderedDict([('vision_embedding', <polygraphy.comparator.compare.OutputCompareResult object at 0x7e4a8410a9e0>)])])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comparator.compare_accuracy(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
