{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed28111",
   "metadata": {},
   "source": [
    "### Compilation command:\n",
    "```bash\n",
    "\n",
    "/opt/qti-aic/exec/qaic-exec \\\n",
    "    -m=/workspace/vfm_fix_outofrange_fp16.onnx \\\n",
    "    -aic-num-cores=16 -convert-to-fp16 \\\n",
    "    -onnx-define-symbol=batch_size,30 \\\n",
    "    -aic-binary-dir=/workspace/vfm_fix_outofrange_fp16_qpc \\\n",
    "    -aic-hw -aic-hw-version=2.0 -compile-only\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ca8c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "sys.path.append(f\"/opt/qti-aic/dev/lib/{platform.machine()}\")\n",
    "import qaicrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd055e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/opt/qti-aic/examples/apps/qaic-python-sdk/qaic\")\n",
    "import torch\n",
    "\n",
    "import qaic\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84930902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path of QPC generated with qaic-exec\n",
    "qpcPath = '/workspace/vfm_fix_outofrange_fp16_qpc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb2f4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vfm_sess = qaic.Session(model_path= qpcPath+'/programqpc.bin', num_activations=1)\n",
    "vfm_sess.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0916b8",
   "metadata": {},
   "source": [
    "Here we are setting `num_activations = 1` and `set_size = 1`.\n",
    "Additionally, you can provide `device_id` as inference parameters. \n",
    "\n",
    "Please find more details about the options [here](https://docs.qualcomm.com/bundle/resource/topics/AIC_Developer_Guide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95999b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_pixel_values Input shape (30, 3, 14, 14448) and type float32\n",
      "patch_attn_mask Input shape (30, 1, 1032) and type int8\n",
      "Output shape (30, 64, 3584) and type float32\n"
     ]
    }
   ],
   "source": [
    "# Here we are reading out all the input and output shapes/types\n",
    "all_pixel_values_shape, all_pixel_values_type = vfm_sess.model_input_shape_dict['all_pixel_values']\n",
    "patch_attn_mask_shape, patch_attn_mask_type = vfm_sess.model_input_shape_dict['patch_attn_mask']\n",
    "output_shape, output_type = vfm_sess.model_output_shape_dict['vision_embedding']\n",
    "print(f'all_pixel_values Input shape {all_pixel_values_shape} and type {all_pixel_values_type}')\n",
    "print(f'patch_attn_mask Input shape {patch_attn_mask_shape} and type {patch_attn_mask_type}')\n",
    "print(f'Output shape {output_shape} and type {output_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f37b6a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "447.77s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QID 0\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:0\n",
      "QID 1\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:0\n",
      "QID 2\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 3\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 4\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 5\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 6\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 7\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 8\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 9\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 10\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 11\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 12\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 13\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 14\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 15\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 16\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 17\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 18\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 19\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 20\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 21\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 22\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 23\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 24\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 25\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 26\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n",
      "QID 27\n",
      "\tStatus:Ready\n",
      "\tDram Total:31391744 KB\n",
      "\tNsp Free:16\n"
     ]
    }
   ],
   "source": [
    "## Check health of the cards before deploying the inference. \n",
    "## Status:Ready indicates that the card is in good health and ready to accept inferences\n",
    "## Status:Error indicates that the card is not in good health. Please contact the system administrator\n",
    "!/opt/qti-aic/tools/qaic-util -q | grep -e \"Status\" -e \"QID\" -e \"Nsp Free\" -e \"Dram Total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332eaa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134694/2092300747.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  all_pixel_values = torch.load('/workspace/inputs/all_pixel_values.pkl')\n",
      "/tmp/ipykernel_134694/2092300747.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  patch_attn_mask = torch.load('/workspace/inputs/patch_attn_mask.pkl')\n"
     ]
    }
   ],
   "source": [
    "# NumPy\n",
    "import numpy as np\n",
    "all_pixel_values = np.load(\n",
    "    # '/workspace/models/vfm/test_data/onnx_input_sample[0].npy'\n",
    "    # \"/workspace/onnx_input_sample[0].np.npy\"\n",
    "    \"/workspace/all_pixel_values_lulu.npy\"\n",
    "    )\n",
    "patch_attn_mask = np.load(\n",
    "    # '/workspace/models/vfm/test_data/onnx_input_sample[1].npy'\n",
    "    # \"/workspace/onnx_input_sample[1].np.npy\"\n",
    "    \"/workspace/patch_attn_mask_lulu.npy\"\n",
    "    )\n",
    "\n",
    "# Create a input dictionary for given input.\n",
    "input_dict = {\n",
    "    \"all_pixel_values\": all_pixel_values,\n",
    "    \"patch_attn_mask\" : patch_attn_mask,\n",
    "    }\n",
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d497145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vision_embedding': array([[[-1.7460938 , -0.28100586, -0.4387207 , ...,  1.3291016 ,\n",
       "           0.4580078 ,  0.43139648],\n",
       "         [-1.3994141 ,  0.83984375,  0.1743164 , ...,  1.8408203 ,\n",
       "           1.6923828 ,  0.62890625],\n",
       "         [-0.9941406 , -1.5380859 ,  0.5493164 , ...,  0.98291016,\n",
       "           1.0703125 , -0.03829956],\n",
       "         ...,\n",
       "         [-0.46606445,  0.14196777,  0.0769043 , ...,  0.43310547,\n",
       "           0.515625  ,  0.28710938],\n",
       "         [-0.5024414 , -1.4091797 , -0.3149414 , ...,  2.0996094 ,\n",
       "          -0.6435547 , -0.33618164],\n",
       "         [-1.1113281 , -1.8867188 ,  1.0888672 , ...,  1.7539062 ,\n",
       "           0.3449707 , -0.19812012]],\n",
       " \n",
       "        [[-1.2880859 , -0.32788086, -0.6669922 , ...,  1.1943359 ,\n",
       "           0.8183594 ,  0.23413086],\n",
       "         [-1.6005859 , -0.3383789 ,  0.64501953, ...,  1.4648438 ,\n",
       "           2.8730469 ,  0.34106445],\n",
       "         [-0.9746094 , -0.6689453 ,  0.5048828 , ...,  0.35009766,\n",
       "           1.3671875 , -0.3125    ],\n",
       "         ...,\n",
       "         [-0.5048828 ,  0.01780701,  0.10888672, ...,  0.4807129 ,\n",
       "           0.73535156,  0.17614746],\n",
       "         [ 1.0068359 ,  0.39086914, -0.3491211 , ...,  0.8691406 ,\n",
       "           0.23425293,  0.26660156],\n",
       "         [-1.1669922 , -1.1035156 ,  0.14697266, ...,  0.30517578,\n",
       "           0.9169922 , -0.53466797]],\n",
       " \n",
       "        [[-1.1152344 , -0.13110352, -0.6503906 , ...,  1.2509766 ,\n",
       "           0.7241211 ,  0.27270508],\n",
       "         [-1.0996094 ,  0.28759766,  0.15588379, ...,  0.9194336 ,\n",
       "           2.1289062 , -0.06015015],\n",
       "         [-0.96972656, -0.9916992 ,  0.5566406 , ...,  0.7006836 ,\n",
       "           1.3701172 , -0.4814453 ],\n",
       "         ...,\n",
       "         [-0.28222656,  0.07965088, -0.11767578, ...,  0.04095459,\n",
       "           0.64697266,  0.31835938],\n",
       "         [ 0.6308594 ,  0.16723633,  0.1694336 , ...,  1.3886719 ,\n",
       "           0.47485352,  0.6933594 ],\n",
       "         [-0.9375    , -0.8754883 ,  0.47802734, ...,  0.82958984,\n",
       "           0.79833984, -0.35668945]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.6542969 , -0.44311523, -0.50390625, ...,  1.5683594 ,\n",
       "           0.25976562,  0.43310547],\n",
       "         [-1.34375   ,  0.38110352,  0.64501953, ...,  1.2236328 ,\n",
       "           2.2832031 ,  0.97314453],\n",
       "         [-1.4589844 , -1.5927734 ,  0.72753906, ...,  1.4101562 ,\n",
       "           0.9550781 ,  0.28637695],\n",
       "         ...,\n",
       "         [-0.6616211 ,  0.15319824, -0.00608826, ...,  0.29003906,\n",
       "           0.6274414 ,  0.4111328 ],\n",
       "         [-0.22045898, -1.0566406 ,  0.00968933, ...,  1.8818359 ,\n",
       "          -0.77441406, -0.08825684],\n",
       "         [-0.9838867 , -1.9296875 ,  1.0224609 , ...,  2.1035156 ,\n",
       "           0.04174805,  0.15356445]],\n",
       " \n",
       "        [[-0.8251953 , -0.7714844 , -0.73583984, ...,  1.4287109 ,\n",
       "           0.74609375,  0.4375    ],\n",
       "         [-0.83984375,  0.29492188,  0.18273926, ...,  0.08459473,\n",
       "           1.7978516 ,  0.40600586],\n",
       "         [-0.6694336 , -0.90283203,  0.41210938, ...,  0.7475586 ,\n",
       "           1.0361328 ,  0.23083496],\n",
       "         ...,\n",
       "         [-0.07958984,  0.23059082, -0.12097168, ..., -0.0692749 ,\n",
       "           0.5839844 ,  0.32421875],\n",
       "         [ 1.2158203 ,  0.4555664 ,  0.59521484, ...,  0.32739258,\n",
       "           0.32592773,  0.53466797],\n",
       "         [-0.33129883, -0.82177734,  0.32202148, ...,  0.70751953,\n",
       "           0.44873047,  0.63720703]],\n",
       " \n",
       "        [[-1.0654297 , -0.6503906 , -0.7553711 , ...,  1.3710938 ,\n",
       "           0.67089844,  0.42919922],\n",
       "         [-0.55371094, -0.06689453,  0.44677734, ...,  0.46948242,\n",
       "           1.2197266 ,  0.1538086 ],\n",
       "         [-1.0039062 , -0.8027344 ,  0.49853516, ...,  1.0478516 ,\n",
       "           1.1416016 ,  0.01177979],\n",
       "         ...,\n",
       "         [-0.9448242 , -0.02456665, -0.1973877 , ...,  0.7626953 ,\n",
       "           0.7080078 ,  0.2836914 ],\n",
       "         [ 1.1689453 , -0.12939453,  0.44482422, ...,  0.21936035,\n",
       "           0.6567383 ,  0.8154297 ],\n",
       "         [-0.36816406, -0.9506836 ,  0.1050415 , ...,  0.8911133 ,\n",
       "           0.3161621 ,  0.37304688]]], dtype=float32)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the model on Qualcomm Cloud AI 100\n",
    "output = vfm_sess.run(input_dict)\n",
    "output['vision_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5894005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model outputs against reference outputs\n",
    "import numpy as np\n",
    "import torch\n",
    "my_vision_embedding = torch.load('/workspace/models/vfm/test_data/vision_embedding.pt', map_location='cpu', weights_only=True)\n",
    "# np.mean(np.abs(my_vision_embedding.to(torch.float32).cpu().numpy() - output['vision_embedding']))\n",
    "np.testing.assert_allclose(my_vision_embedding.to(torch.float32).cpu().numpy(), output['vision_embedding'], rtol=1e-3, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6465d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(output['vision_embedding'], '/workspace/outputs/vision_embedding_qpc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cf8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the session to release the NSP cores\n",
    "vfm_sess.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
